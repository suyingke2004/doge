# 测试用例：任务三 - RAG检索与生成

## 1. RAG工具检索功能测试

-   **用例1.1：相关内容检索**
    -   **前置条件**：知识库中包含关于“如何应对焦虑”的内容。
    -   **操作**：调用 `knowledge_base_search.py` 中的 `search_knowledge_base` 函数，输入查询 “我感到很焦虑，怎么办？”
    -   **预期结果**：函数返回的文本内容与“应对焦虑”高度相关。

-   **用例1.2：不相关内容检索**
    -   **前置条件**：知识库中不包含关于“如何做饭”的内容。
    -   **操作**：调用 `search_knowledge_base` 函数，输入查询 “今天晚上吃什么？”
    -   **预期结果**：函数返回空结果或相关性极低的文本。

-   **用例1.3：查询向量化一致性**
    -   **前置条件**：无。
    -   **操作**：检查 `search_knowledge_base` 函数中用于查询的嵌入模型。
    -   **预期结果**：该模型与任务二中用于知识库构建的嵌入模型必须是同一个。

## 2. Agent集成测试

-   **用例2.1：正确触发RAG工具**
    -   **前置条件**：Agent已配置好RAG工具。
    -   **操作**：用户输入明确的求助类问题，如 “你能给我一些关于拖延症的建议吗？”
    -   **预期结果**：Agent的内部日志或调试信息显示，`search_knowledge_base` 工具被成功调用。

-   **用例2.2：不触发RAG工具**
    -   **前置条件**：Agent已配置好RAG工具。
    -   **操作**：用户输入普通闲聊或情绪抒发类内容，如 “今天天气真好” 或 “我今天好难过”。
    -   **预期结果**：Agent不调用 `search_knowledge_base` 工具，而是执行普通的共情或闲聊回复逻辑。

## 3. 回复生成测试

-   **用例3.1：回复内容与知识相关**
    -   **前置条件**：RAG工具检索到了关于“深呼吸放松法”的知识。
    -   **操作**：用户提问“如何快速缓解紧张？”
    -   **预期结果**：AI最终生成的回复中，包含了关于“深呼吸”的建议。

-   **用例3.2：回复风格符合“小狗文学”**
    -   **前置条件**：同上。
    -   **操作**：检查AI生成的回复文本。
    -   **预期结果**：回复不是生硬的知识复述，而是以“小狗”的口吻和视角进行转述。例如，出现“（小狗歪着头想了想）书上说，你可以试试像小狗打哈欠一样，深深地吸一口气，再慢慢吐出来……”等类似表达。

-   **用例3.3：引用来源（可选，但推荐）**
    -   **前置条件**：同上。
    -   **操作**：检查AI生成的回复文本。
    -   **预期结果**：在回复的末尾或适当位置，以不破坏沉浸感的方式，注明知识来源，如“（这段知识来自《情绪急救》哦）”。
